
import uuid
import logging
from typing import List, Optional, Tuple
from datetime import date, datetime, timedelta
import math
import httpx
import pandas as pd
import numpy as np
from scipy import optimize
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc, func, and_
from fastapi import HTTPException, Depends

from app.core.database import get_db
from app.features.wealth.models import InvestmentHolding, InvestmentSnapshot, InvestmentMappingRule, AssetType
from app.features.wealth import schemas
from app.features.transactions.models import Transaction

logger = logging.getLogger(__name__)

# Try importing Prophet, handle if missing (though it should be there)
try:
    from prophet import Prophet
except ImportError:
    Prophet = None
    logger.warning("Facebook Prophet not installed. Forecasting will be disabled.")

try:
    import yfinance as yf
except ImportError:
    yf = None
    logger.warning("yfinance not installed. Stock data will be unavailable.")

class WealthService:
    def __init__(self, db: AsyncSession = Depends(get_db)):
        self.db = db

    async def get_holdings(self, user_id: uuid.UUID) -> List[InvestmentHolding]:
        stmt = select(InvestmentHolding).where(InvestmentHolding.user_id == user_id)
        result = await self.db.execute(stmt)
        return result.scalars().all()

    async def get_holding_details(self, holding_id: uuid.UUID, user_id: uuid.UUID) -> InvestmentHolding:
        # Use selectinload to fetch snapshots efficiently
        from sqlalchemy.orm import selectinload
        stmt = (
            select(InvestmentHolding)
            .where(InvestmentHolding.id == holding_id, InvestmentHolding.user_id == user_id)
            .options(selectinload(InvestmentHolding.snapshots))
        )
        result = await self.db.execute(stmt)
        holding = result.scalar_one_or_none()
        
        if not holding:
            raise ValueError("Holding not found")
            
        return holding

    async def create_holding(self, user_id: uuid.UUID, data: schemas.InvestmentHoldingCreate) -> InvestmentHolding:
        """Create a new holding. If existing holdings data provided, create synthetic snapshots."""
        from dateutil.relativedelta import relativedelta
        
        # Extract onboarding fields
        current_units = data.current_units
        total_invested = data.total_invested
        start_date = data.investment_start_date
        investment_type = data.investment_type
        
        # Create holding (exclude onboarding fields from model)
        holding_data = data.model_dump(exclude={'current_units', 'total_invested', 'investment_start_date', 'investment_type'})
        holding = InvestmentHolding(**holding_data, user_id=user_id)
        
        # Set initial values if provided
        if total_invested:
            holding.total_invested = total_invested
        if current_units and holding.api_source in ['MFAPI', 'YFINANCE']:
            # Fetch current NAV to calculate current value
            try:
                current_nav = await self.get_asset_price(holding, date.today())
                holding.current_value = current_units * current_nav
            except:
                holding.current_value = total_invested if total_invested else 0
        
        self.db.add(holding)
        await self.db.commit()
        await self.db.refresh(holding)
        
        # If user provided existing holdings data, create synthetic snapshots
        if current_units and total_invested and start_date:
            await self._create_synthetic_snapshots(
                holding=holding,
                current_units=current_units,
                total_invested=total_invested,
                start_date=start_date,
                investment_type=investment_type or 'SIP'
            )
            
            # Calculate XIRR from synthetic data
            try:
                holding.xirr = await self.calculate_xirr(holding.id)
            except:
                logger.warning(f"Could not calculate XIRR for holding {holding.id}")
            
            await self.db.commit()
            await self.db.refresh(holding)
        
        return holding
    
    async def _create_synthetic_snapshots(
        self,
        holding: InvestmentHolding,
        current_units: float,
        total_invested: float,
        start_date: date,
        investment_type: str
    ):
        """Create synthetic snapshots for onboarding with existing holdings."""
        from dateutil.relativedelta import relativedelta
        
        today = date.today()
        
        # Get current NAV
        try:
            current_nav = await self.get_asset_price(holding, today)
        except:
            current_nav = total_invested / current_units if current_units > 0 else 1.0
        
        # Estimate start NAV (reverse calculate from current value)
        # Assuming linear growth for simplicity
        start_nav = total_invested / current_units if current_units > 0 else current_nav
        
        if investment_type == 'LUMPSUM':
            # Create 2 snapshots: start and today
            snapshots = [
                InvestmentSnapshot(
                    holding_id=holding.id,
                    user_id=holding.user_id,
                    captured_at=start_date,
                    units_held=current_units,
                    price_per_unit=start_nav,
                    total_value=total_invested,
                    amount_invested_delta=total_invested,
                    is_projected=True
                ),
                InvestmentSnapshot(
                    holding_id=holding.id,
                    user_id=holding.user_id,
                    captured_at=today,
                    units_held=current_units,
                    price_per_unit=current_nav,
                    total_value=current_units * current_nav,
                    amount_invested_delta=0,
                    is_projected=False  # Today's data is real
                )
            ]
        
        elif investment_type == 'SIP':
            # Calculate months between start and today
            months_diff = (today.year - start_date.year) * 12 + (today.month - start_date.month)
            
            if months_diff <= 0:
                months_diff = 1
            
            # Calculate average SIP amount
            sip_amount = total_invested / months_diff
            
            # Create monthly snapshots
            snapshots = []
            running_units = 0.0
            running_invested = 0.0
            
            for i in range(months_diff + 1):
                snap_date = start_date + relativedelta(months=i)
                if snap_date > today:
                    break
                
                # Estimate units accumulated so far
                invested_so_far = sip_amount * (i + 1)
                units_so_far = (current_units / total_invested) * invested_so_far
                
                # Linear NAV interpolation
                nav_progress = i / months_diff if months_diff > 0 else 1
                estimated_nav = start_nav + (current_nav - start_nav) * nav_progress
                
                running_units = units_so_far
                running_invested = invested_so_far
                
                is_today = snap_date == today
                
                snapshots.append(InvestmentSnapshot(
                    holding_id=holding.id,
                    user_id=holding.user_id,
                    captured_at=snap_date,
                    units_held=running_units,
                    price_per_unit=estimated_nav,
                    total_value=running_units * estimated_nav,
                    amount_invested_delta=sip_amount,
                    is_projected=not is_today  # Only today's is real
                ))
        
        else:
            # Unknown type, create simple lumpsum
            snapshots = [
                InvestmentSnapshot(
                    holding_id=holding.id,
                    user_id=holding.user_id,
                    captured_at=today,
                    units_held=current_units,
                    price_per_unit=current_nav,
                    total_value=current_units * current_nav,
                    amount_invested_delta=total_invested,
                    is_projected=True
                )
            ]
        
        self.db.add_all(snapshots)
        await self.db.commit()
        
        logger.info(f"Created {len(snapshots)} synthetic snapshots for holding {holding.id}")

    # --- Pricing & Sync Logic ---

    async def fetch_nav_mfapi(self, scheme_code: str, target_date: Optional[date] = None) -> float:
        """Fetch NAV from MFAPI.in. If date provided, find closest NAV. Else latest."""
        url = f"https://api.mfapi.in/mf/{scheme_code}"
        async with httpx.AsyncClient() as client:
            resp = await client.get(url)
            if resp.status_code != 200:
                raise ValueError(f"Invalid MFAPI code: {scheme_code}")
            data = resp.json().get("data", [])
            
        if not data:
            raise ValueError("No data found for scheme")

        # Data is list of {date: "dd-mm-yyyy", nav: "str"} sorted desc
        
        if not target_date:
            return float(data[0]["nav"])
        
        # Find match for date
        target_str = target_date.strftime("%d-%m-%Y")
        
        # Linear search (list is usually sorted desc)
        for entry in data:
            if entry["date"] == target_str:
                return float(entry["nav"])
            
            # If we passed the date (data is strictly descending), we might need to take prev or next
            # Simplified: Exact match or throw/fallback to closest
            # Since MF NAVs are daily, let's try to match.
            
        # If strict match failed, let's try parsing and finding closest
        # This is expensive? Maybe just error for ecosystem simplicity first.
        # Fallback: Use latest if today, else error.
        raise ValueError(f"No NAV found for date {target_str}")

    async def search_mutual_funds(self, query: str) -> List[dict]:
        """Search mutual funds by name using MFAPI.in"""
        if len(query) < 3:
            return []
        
        url = f"https://api.mfapi.in/mf/search?q={query}"
        async with httpx.AsyncClient() as client:
            try:
                resp = await client.get(url, timeout=10.0)
                if resp.status_code == 200:
                    return resp.json()
                return []
            except Exception as e:
                logger.error(f"MFAPI search failed: {e}")
                return []

    async def fetch_price_yfinance(self, ticker: str, target_date: Optional[date] = None) -> float:
        if not yf:
            raise ValueError("yfinance library missing")
        
        # yfinance logic
        ticker_obj = yf.Ticker(ticker)
        if target_date:
            # fetch history around date
            start = target_date
            end = target_date + timedelta(days=1)
            hist = ticker_obj.history(start=start, end=end)
            if not hist.empty:
                return float(hist["Close"].iloc[0])
            else:
                 # Try slightly wider window for weekends/holidays
                 end = target_date + timedelta(days=4)
                 hist = ticker_obj.history(start=start, end=end)
                 if not hist.empty:
                     return float(hist["Close"].iloc[0])
                 raise ValueError("No stock price data for date")
        else:
             # Latest
             hist = ticker_obj.history(period="1d")
             if not hist.empty:
                 return float(hist["Close"].iloc[-1])
             raise ValueError("No current stock price data")

    async def get_asset_price(self, holding: InvestmentHolding, target_date: Optional[date] = None) -> float:
        if holding.asset_type in [AssetType.FD, AssetType.RD, AssetType.PF, AssetType.GRATUITY]:
            # Fixed income / Computed logic
            # For now return 1.0 or user manually handled. 
            # Actually, PF/Gratuity have specific formulas, but "price per unit" concept applies vaguely
            # if we treat Unit=1 and Value = computed.
            return 1.0 

        if not holding.ticker_symbol:
             return 1.0 # Fallback for manual assets

        if holding.api_source == "MFAPI":
            return await self.fetch_nav_mfapi(holding.ticker_symbol, target_date)
        elif holding.api_source == "YFINANCE":
            return await self.fetch_price_yfinance(holding.ticker_symbol, target_date)
            
        return 1.0

    # --- Transaction Mapping & Logic ---

    async def process_transaction_match(self, transaction: Transaction) -> bool:
        """
        Called by SyncService/TransactionService.
        Attempts to map a transaction to a holding and update it.
        Returns True if mapped and processed.
        """
        if transaction.amount > 0:
             # Income? Or Refund? Typically wealth investment is outgoing (negative amount in transaction usually denotes speinding)
             # But if "Investment" category, a DEBIT (negative) is a BUY. A CREDIT (positive) is a SELL.
             # Grip stores expenses as negative? Or positive?
             # Standard Grip: Amount is positive for expense if type is DEBIT?
             # Let's check SyncService: final_amount = -abs(amount) for Debit.
             # So Expense is negative.
             pass

        # Find matching rules
        # We need to match pattern against merchant_name or remarks or even raw extraction context if possible.
        # Here we only have transaction details.
        
        stmt = select(InvestmentMappingRule).where(InvestmentMappingRule.user_id == transaction.user_id)
        result = await self.db.execute(stmt)
        rules = result.scalars().all()
        
        matched_rule = None
        search_text = f"{transaction.merchant_name} {transaction.remarks or ''}".lower()
        
        for rule in rules:
            if rule.match_type == "CONTAINS" and rule.pattern.lower() in search_text:
                matched_rule = rule
                break
            elif rule.match_type == "EXACT" and rule.pattern.lower() == search_text:
                matched_rule = rule
                break
                
        if not matched_rule:
            return False
            
        # Match found! Execute Logic.
        holding_id = matched_rule.holding_id
        await self.add_transaction_to_holding(transaction, holding_id)
        return True

    async def add_transaction_to_holding(self, transaction: Transaction, holding_id: uuid.UUID):
        """
        Calculates units and updates snapshot.
        Transaction Amount < 0 => BUY (usually).
        Transaction Amount > 0 => SELL.
        Wait, standard logic: Debit (negative) -> Money leaves account -> Enters Investment -> Buy.
        Credit (positive) -> Money enters account -> Leaves Investment -> Sell.
        """
        holding = await self.db.get(InvestmentHolding, holding_id)
        if not holding:
            return

        amount = transaction.amount
        txn_date = transaction.transaction_date or date.today()
        
        # Calculate Amount Invested Delta
        # If Amount = -1000 (Debit), we invested 1000. Delta = +1000.
        # If Amount = +1000 (Credit), we sold 1000. Delta = -1000? 
        # Actually XIRR expects: Dates, Cashflow.
        # Buy: -1000 cashflow for user. 
        # But here 'amount_invested_delta' tracks what went INTO the asset.
        invested_delta = float(-amount)
        
        # Get Price
        try:
            price = await self.get_asset_price(holding, txn_date)
        except Exception as e:
            logger.error(f"Failed to fetch price for {holding.name}: {e}")
            price = 1.0 # Fallback? Or fail?
            
        units = 0.0
        if price > 0:
            units = invested_delta / price
            
        # Create Snapshot for this specific transaction action
        # Note: We might already have a snapshot for this day? 
        # If so, update it? Or just insert new one?
        # Prophet works better with daily aggregates. 
        # But we also want to track the explicit "Buy" action.
        # Let's see models: "captured_at" is Date. Unique index? 
        # "Index heavily on (user_id, captured_at)" was requested.
        # We should merge with existing snapshot if exists for that day.
        
        stmt = select(InvestmentSnapshot).where(
            and_(
                InvestmentSnapshot.holding_id == holding_id,
                InvestmentSnapshot.captured_at == txn_date
            )
        )
        existing = (await self.db.execute(stmt)).scalar_one_or_none()
        
        if existing:
            existing.units_held += units
            existing.amount_invested_delta += invested_delta
            # Update total value based on new units * price (which we just fetched)
            existing.price_per_unit = price
            existing.total_value = existing.units_held * price
        else:
            # We need to know previous units to add to?
            # Or is this snapshot just the delta? 
            # "Time-series table... total_value". It implies Cumulative State.
            # So we need previous day's units.
            
            # Find closest previous snapshot
            prev_stmt = (
                select(InvestmentSnapshot)
                .where(
                    InvestmentSnapshot.holding_id == holding_id,
                    InvestmentSnapshot.captured_at < txn_date
                )
                .order_by(desc(InvestmentSnapshot.captured_at))
                .limit(1)
            )
            prev = (await self.db.execute(prev_stmt)).scalar_one_or_none()
            prev_units = prev.units_held if prev else 0.0
            
            new_units = prev_units + units
            snap = InvestmentSnapshot(
                holding_id=holding_id,
                user_id=transaction.user_id,
                captured_at=txn_date,
                units_held=new_units,
                price_per_unit=price,
                total_value=new_units * price,
                amount_invested_delta=invested_delta
            )
            self.db.add(snap)
            
        # Also, if we added a transaction in the PAST, we must propagate unit changes to ALL future snapshots.
        # This is complex. "Event sourcing" preferred but expensive.
        # We can run a "recalculate_holding" task.
        await self.recalculate_holding_history(holding_id)
        
        await self.db.commit()

    async def recalculate_holding_history(self, holding_id: uuid.UUID):
        """
        Re-runs the chain of units from start to finish.
        Used when inserting/updating a past transaction.
        """
        snapshots_stmt = (
            select(InvestmentSnapshot)
            .where(InvestmentSnapshot.holding_id == holding_id)
            .order_by(InvestmentSnapshot.captured_at)
        )
        snapshots = (await self.db.execute(snapshots_stmt)).scalars().all()
        
        running_units = 0.0
        total_invested = 0.0
        
        for snap in snapshots:
            # We assume amount_invested_delta is the source of truth for "Activity" on that day
            # If units were derived from price, we might need to preserve that ratio.
            # But simpler: Re-calculate units from delta / price.
            
            if snap.price_per_unit <= 0: snap.price_per_unit = 1.0 # Safety
            
            # Re-derive units for this day's action (convert Decimal to float)
            day_units = float(snap.amount_invested_delta) / float(snap.price_per_unit)
            
            running_units += day_units
            total_invested += float(snap.amount_invested_delta)
            
            snap.units_held = running_units
            snap.total_value = snap.units_held * float(snap.price_per_unit)
            
        # Update Holding Master Record
        holding = await self.db.get(InvestmentHolding, holding_id)
        if snapshots:
            holding.current_value = snapshots[-1].total_value
            holding.total_invested = total_invested
            holding.last_updated_at = datetime.now()
            
            # Trigger XIRR calc
            holding.xirr = self.calculate_xirr(snapshots)

    def calculate_xirr(self, snapshots: List[InvestmentSnapshot]) -> float:
        """
        Calculate XIRR based on input flows + current value.
        Flows: (Date, -amount_invested_delta)
        Terminal: (Last Date, +total_value)
        """
        if not snapshots:
            return 0.0
            
        dates = []
        amounts = []
        
        for s in snapshots:
            if abs(s.amount_invested_delta) > 0.01:
                dates.append(s.captured_at)
                # In XIRR:
                # Outflow (Investment) is negative.
                # Here amount_invested_delta is +ve for investment.
                # So we flip sign => -s.amount_invested_delta
                amounts.append(-s.amount_invested_delta)
        
        # Terminal Value
        last_snap = snapshots[-1]
        dates.append(last_snap.captured_at)
        amounts.append(last_snap.total_value) # Positive inflow if we sold it all today
        
        if len(amounts) < 2:
            return 0.0
            
        # Scipy XIRR Logic
        # Newton-Raphson method
        # 0 = sum( amount_i / (1 + xirr)^((date_i - date_0)/365) )
        
        try:
            dates_ord = [d.toordinal() for d in dates]
            d0 = dates_ord[0]
            
            def xnpv(rate):
                return sum([a / pow(1 + rate, (d - d0) / 365.0) for a, d in zip(amounts, dates_ord)])
                
            def xnpv_prime(rate):
                 return sum([- (d - d0) / 365.0 * a / pow(1 + rate, (d - d0) / 365.0 + 1) for a, d in zip(amounts, dates_ord)])

            # Initial guess 0.1 (10%)
            # If newton fails, return 0
            res = optimize.newton(xnpv, 0.1, fprime=xnpv_prime, maxiter=50)
            return res * 100 # Return percentage
        except Exception:
            return 0.0

    # --- Forecasting ---

    async def generate_forecast(self, user_id: uuid.UUID, years: int = 10) -> schemas.ForecastResponse:
        if not Prophet:
            return schemas.ForecastResponse(forecast=[], summary_text="Prophet forecasting unavailable.")
            
        # 1. Aggregate total portfolio value by day
        stmt = (
            select(
                InvestmentSnapshot.captured_at,
                func.sum(InvestmentSnapshot.total_value).label("total_val")
            )
            .where(InvestmentSnapshot.user_id == user_id)
            .group_by(InvestmentSnapshot.captured_at)
            .order_by(InvestmentSnapshot.captured_at)
        )
        
        rows = (await self.db.execute(stmt)).all()
        if len(rows) < 30: # Need some history
            return schemas.ForecastResponse(forecast=[], summary_text="Insufficient data for forecasting (need >30 data points).")
            
        df = pd.DataFrame(rows, columns=['ds', 'y'])
        
        # Prophet setup
        m = Prophet(daily_seasonality=False, yearly_seasonality=True)
        m.fit(df)
        
        future = m.make_future_dataframe(periods=years * 365)
        forecast = m.predict(future)
        
        # Extract relevant points
        # Filter strictly future
        last_date = df['ds'].max()
        future_forecast = forecast[forecast['ds'] > last_date]
        
        # Downsample to weekly or monthly to save bandwidth? 
        # API requires returning 'ForecastPoint'.
        
        result_points = []
        for index, row in future_forecast.iterrows():
            # Monthly sampling
            if row['ds'].day == 1:
                result_points.append(schemas.ForecastPoint(
                    date=row['ds'].date(),
                    yhat=row['yhat'],
                    yhat_lower=row['yhat_lower'],
                    yhat_upper=row['yhat_upper']
                ))
                
        # Calculate summary metrics
        final_val = result_points[-1].yhat if result_points else 0
        current_val = rows[-1].total_val
        growth = ((final_val - current_val) / current_val) * 100 if current_val > 0 else 0
        
        summary = f"Projected growth: {growth:.1f}%"
        
        return schemas.ForecastResponse(
            forecast=result_points,
            history=[
                schemas.ForecastPoint(
                    date=row.captured_at,
                    yhat=row.total_val,
                    yhat_lower=row.total_val,
                    yhat_upper=row.total_val
                ) for row in rows
            ],
            summary_text=summary
        )

    async def map_transaction(self, transaction_id: uuid.UUID, holding_id: uuid.UUID, create_rule: bool) -> bool:
        transaction = await self.db.get(Transaction, transaction_id)
        if not transaction:
            raise ValueError("Transaction not found")
            
        await self.add_transaction_to_holding(transaction, holding_id)
        
        if create_rule:
            # Create a rule for this merchant
            # Check if exists
            stmt = select(InvestmentMappingRule).where(
                and_(
                    InvestmentMappingRule.user_id == transaction.user_id,
                    InvestmentMappingRule.pattern == transaction.merchant_name
                )
            )
            existing = (await self.db.execute(stmt)).scalar_one_or_none()
            if not existing:
                rule = InvestmentMappingRule(
                    user_id=transaction.user_id,
                    holding_id=holding_id,
                    pattern=transaction.merchant_name,
                    match_type="CONTAINS" # Safe default
                )
                self.db.add(rule)
                await self.db.commit()
                
        return True

    async def sync_all_holdings_prices(self):
        """
        Fetches latest price for all holdings and updates snapshots for today.
        """
        # Fetch all active holdings
        stmt = select(InvestmentHolding)
        result = await self.db.execute(stmt)
        holdings = result.scalars().all()
        
        today = date.today()
        
        for holding in holdings:
            if not holding.ticker_symbol:
                continue
                
            try:
                price = await self.get_asset_price(holding, today)
                if price <= 0: continue
                
                # Check for existing snapshot today to update
                snap_stmt = select(InvestmentSnapshot).where(
                    and_(
                        InvestmentSnapshot.holding_id == holding.id,
                        InvestmentSnapshot.captured_at == today
                    )
                )
                existing = (await self.db.execute(snap_stmt)).scalar_one_or_none()
                
                if existing:
                    existing.price_per_unit = price
                    existing.total_value = existing.units_held * price
                else:
                    # Create new snapshot based on previous day's units
                    prev_stmt = (
                        select(InvestmentSnapshot)
                        .where(
                            InvestmentSnapshot.holding_id == holding.id,
                            InvestmentSnapshot.captured_at < today
                        )
                        .order_by(desc(InvestmentSnapshot.captured_at))
                        .limit(1)
                    )
                    prev = (await self.db.execute(prev_stmt)).scalar_one_or_none()
                    units = prev.units_held if prev else 0.0
                    
                    if units > 0:
                        new_snap = InvestmentSnapshot(
                            holding_id=holding.id,
                            user_id=holding.user_id,
                            captured_at=today,
                            units_held=units,
                            price_per_unit=price,
                            total_value=units * price,
                            amount_invested_delta=0.0
                        )
                        self.db.add(new_snap)
                        
                # Update holding master
                holding.current_value = (existing.units_held * price) if existing else (units * price)
                holding.last_updated_at = datetime.now()
                
            except Exception as e:
                logger.error(f"Failed to sync price for {holding.name}: {e}")
                
        await self.db.commit()

    # --- CAMS Import Feature ---
    
    async def import_cams_statement(
        self, 
        user_id: uuid.UUID, 
        request: schemas.CAMSImportRequest
    ) -> schemas.CAMSImportResponse:
        """
        Import CAMS statement transactions and create/update holdings.
        Detects SIP patterns, step-ups, and skips automatically.
        """
        holdings_created = 0
        holdings_updated = 0
        transactions_processed = 0
        sip_patterns_detected = 0
        errors = []
        
        # Group transactions by scheme name
        from collections import defaultdict
        scheme_groups = defaultdict(list)
        
        for txn in request.transactions:
            scheme_groups[txn.scheme_name].append(txn)
        
        # Process each scheme
        for scheme_name, txns in scheme_groups.items():
            try:
                # Sort transactions by date
                txns.sort(key=lambda x: x.transaction_date)
                
                # Check if holding exists
                stmt = select(InvestmentHolding).where(
                    and_(
                        InvestmentHolding.user_id == user_id,
                        InvestmentHolding.name == scheme_name
                    )
                )
                holding = (await self.db.execute(stmt)).scalar_one_or_none()
                
                if not holding and request.auto_create_holdings:
                    # Create new holding
                    holding = InvestmentHolding(
                        user_id=user_id,
                        name=scheme_name,
                        asset_type=AssetType.MUTUAL_FUND,
                        api_source="MFAPI",
                        current_value=0.0,
                        total_invested=0.0
                    )
                    self.db.add(holding)
                    await self.db.commit()
                    await self.db.refresh(holding)
                    holdings_created += 1
                elif holding:
                    holdings_updated += 1
                else:
                    errors.append(f"No holding found for {scheme_name} and auto_create is False")
                    continue
                
                # Detect SIP pattern if requested
                is_sip_pattern = False
                if request.detect_sip_patterns:
                    is_sip_pattern = self._detect_sip_pattern(txns)
                    if is_sip_pattern:
                        sip_patterns_detected += 1
                
                # Process each transaction
                running_units = 0.0
                prev_txn = None
                
                for txn in txns:
                    t_type = txn.transaction_type.lower()
                    
                    # Broad matching for Buy transactions
                    is_buy = any(x in t_type for x in ['purchase', 'sip', 'switch in', 'dividend', 'invest', 'reinvest'])
                    # Broad matching for Sell transactions 
                    is_sell = any(x in t_type for x in ['redemption', 'sell', 'switch out', 'withdraw'])

                    if is_buy:
                        # Buy transaction
                        running_units += txn.units
                        invested_delta = txn.amount
                        
                        # Detect step-up or skip
                        is_step_up = False
                        is_skip = False
                        skip_reason = None
                        sip_amount = None
                        metadata = {}
                        
                        if is_sip_pattern and prev_txn:
                            # Check for step-up
                            if abs(txn.amount - prev_txn.amount) > 100:  # Threshold
                                is_step_up = True
                                metadata['previous_amount'] = prev_txn.amount
                                metadata['change_percentage'] = ((txn.amount - prev_txn.amount) / prev_txn.amount) * 100
                            
                            # Check for skip (gap > 35 days for monthly SIP)
                            days_gap = (txn.transaction_date - prev_txn.transaction_date).days
                            if days_gap > 35:
                                is_skip = True
                                skip_reason = f"Gap of {days_gap} days detected"
                                metadata['skipped_months'] = days_gap // 30
                            
                            sip_amount = txn.amount
                        
                        # Create or update snapshot
                        snap_stmt = select(InvestmentSnapshot).where(
                            and_(
                                InvestmentSnapshot.holding_id == holding.id,
                                InvestmentSnapshot.captured_at == txn.transaction_date
                            )
                        )
                        existing_snap = (await self.db.execute(snap_stmt)).scalar_one_or_none()
                        
                        if existing_snap:
                            existing_snap.units_held = running_units
                            existing_snap.price_per_unit = txn.nav
                            existing_snap.total_value = running_units * txn.nav
                            existing_snap.amount_invested_delta += invested_delta
                        else:
                            snapshot = InvestmentSnapshot(
                                holding_id=holding.id,
                                user_id=user_id,
                                captured_at=txn.transaction_date,
                                units_held=running_units,
                                price_per_unit=txn.nav,
                                total_value=running_units * txn.nav,
                                amount_invested_delta=invested_delta,
                                is_sip=is_sip_pattern,
                                sip_amount=sip_amount,
                                is_step_up=is_step_up,
                                is_skip=is_skip,
                                skip_reason=skip_reason,
                                extra_data=metadata if metadata else None
                            )
                            self.db.add(snapshot)
                        
                        transactions_processed += 1
                        prev_txn = txn
                    
                    elif is_sell:
                        # Sell transaction
                        running_units -= txn.units
                        invested_delta = -txn.amount
                        
                        snapshot = InvestmentSnapshot(
                            holding_id=holding.id,
                            user_id=user_id,
                            captured_at=txn.transaction_date,
                            units_held=running_units,
                            price_per_unit=txn.nav,
                            total_value=running_units * txn.nav,
                            amount_invested_delta=invested_delta
                        )
                        self.db.add(snapshot)
                        transactions_processed += 1
                
                # Update holding totals manually to preserve unit counts from CSV
                # (recalculate_holding_history is destructive if NAV is missing)
                
                # Calculate net investment for this batch
                net_investment = 0.0
                for txn in txns:
                    t_type = txn.transaction_type.lower()
                    if any(x in t_type for x in ['purchase', 'sip', 'switch in', 'dividend', 'invest', 'reinvest']):
                        net_investment += txn.amount
                    elif any(x in t_type for x in ['redemption', 'sell', 'switch out', 'withdraw']):
                        net_investment -= txn.amount
                
                holding.total_invested += net_investment
                
                # Update current value using last known NAV from import
                last_nav = txns[-1].nav if txns else 0.0
                if last_nav > 0:
                     holding.current_value = running_units * last_nav
                
                holding.last_updated_at = datetime.now()
                
                # await self.recalculate_holding_history(holding.id) # DISABLED: Destructive
                
            except Exception as e:
                logger.error(f"Error processing scheme {scheme_name}: {e}")
                errors.append(f"{scheme_name}: {str(e)}")
        
        await self.db.commit()
        
        return schemas.CAMSImportResponse(
            holdings_created=holdings_created,
            holdings_updated=holdings_updated,
            transactions_processed=transactions_processed,
            sip_patterns_detected=sip_patterns_detected,
            errors=errors
        )
    
    def _detect_sip_pattern(self, transactions: List[schemas.CAMSTransaction]) -> bool:
        """Detect if transactions follow a SIP pattern (regular monthly investments)."""
        if len(transactions) < 3:
            return False
        
        # Check for regular intervals (25-35 days)
        intervals = []
        for i in range(1, len(transactions)):
            days = (transactions[i].transaction_date - transactions[i-1].transaction_date).days
            intervals.append(days)
        
        # Most intervals should be 25-35 days (monthly)
        monthly_count = sum(1 for d in intervals if 25 <= d <= 35)
        return monthly_count >= len(intervals) * 0.7  # 70% threshold

    # --- SIP Date-Specific Performance Analysis ---
    
    async def analyze_sip_date_performance(
        self,
        holding_id: uuid.UUID,
        user_id: uuid.UUID
    ) -> schemas.SIPDateAnalysisResponse:
        """
        Analyze user's SIP performance based on actual purchase dates
        and compare with alternative dates (1st, 5th, 10th, 15th, 20th, 25th).
        """
        # Get holding with snapshots
        holding = await self.get_holding_details(holding_id, user_id)
        
        # Filter SIP snapshots only
        sip_snapshots = [s for s in holding.snapshots if s.is_sip and s.amount_invested_delta > 0]
        
        if len(sip_snapshots) < 3:
            raise ValueError("Insufficient SIP data for analysis (need at least 3 SIP transactions)")
        
        # Extract user's most common SIP date
        sip_dates = [s.captured_at.day for s in sip_snapshots]
        from collections import Counter
        most_common_date = Counter(sip_dates).most_common(1)[0][0]
        
        # Calculate average SIP amount
        avg_sip_amount = sum(s.amount_invested_delta for s in sip_snapshots) / len(sip_snapshots)
        
        # Get current NAV
        try:
            current_nav = await self.get_asset_price(holding, date.today())
        except:
            current_nav = sip_snapshots[-1].price_per_unit
        
        # Pre-fetch NAV history for efficiency (Avoid 1000+ API calls)
        nav_history = []
        if holding.ticker_symbol and holding.api_source == "MFAPI":
             nav_history = await self.get_mf_nav_history(holding.ticker_symbol)
        
        # Test all days from 1st to 28th (Timing Alpha)
        alternative_dates = list(range(1, 29))
        
        # Calculate performance for each alternative date
        results = {}
        
        for alt_date in alternative_dates:
            try:
                performance = await self._calculate_date_performance(
                    holding=holding,
                    sip_snapshots=sip_snapshots,
                    target_date=alt_date,
                    avg_sip_amount=avg_sip_amount,
                    current_nav=current_nav,
                    nav_history=nav_history
                )
                results[alt_date] = performance
            except Exception as e:
                # logger.warning(f"Could not calculate performance for date {alt_date}: {e}")
                pass
        
        # Get user's actual performance
        user_performance = results.get(most_common_date)
        
        if not user_performance:
            raise ValueError("Could not calculate user's actual performance")
        
        # Find best alternative
        best_date = max(results.keys(), key=lambda d: results[d].xirr or 0)
        best_performance = results[best_date]
        improvement = best_performance.absolute_return - user_performance.absolute_return
        
        # Generate insight
        insight = self._generate_sip_insight(
            user_date=most_common_date,
            user_perf=user_performance,
            best_date=best_date,
            best_perf=best_performance,
            improvement=improvement
        )
        
        # Historical pattern analysis
        historical_pattern = self._analyze_historical_pattern(
            sip_snapshots=sip_snapshots,
            user_date=most_common_date,
            best_date=best_date
        )
        
        return schemas.SIPDateAnalysisResponse(
            holding_id=holding_id,
            holding_name=holding.name,
            user_sip_date=most_common_date,
            user_performance=user_performance,
            alternatives=results,
            best_alternative={
                "date": best_date,
                "performance": best_performance,
                "improvement": improvement
            },
            insight=insight,
            historical_pattern=historical_pattern
        )
    
    async def _calculate_date_performance(
        self,
        holding: InvestmentHolding,
        sip_snapshots: List[InvestmentSnapshot],
        target_date: int,
        avg_sip_amount: float,
        current_nav: float,
        nav_history: List[dict] = None
    ) -> schemas.SIPDatePerformance:
        """Calculate performance for a specific SIP date."""
        simulated_portfolio = []
        total_units = 0.0
        total_invested = 0.0
        
        # Optimization: Create a lookup map for history if provided
        # nav_lookup = {row['date']: row['nav'] for row in nav_history} # Expensive to build every time?
        # Better: Just linear scan or simple lookup helper if passed efficiently
        
        for snapshot in sip_snapshots:
            # Calculate target date in same month/year
            try:
                target_dt = snapshot.captured_at.replace(day=target_date)
            except ValueError:
                # Handle months with fewer days (e.g., Feb 30)
                from calendar import monthrange
                max_day = monthrange(snapshot.captured_at.year, snapshot.captured_at.month)[1]
                target_dt = snapshot.captured_at.replace(day=min(target_date, max_day))
            
            # Fetch NAV for this alternative date
            # Loop optimization: Use history
            nav = 0.0
            if nav_history:
                nav = self._find_nav_in_history(nav_history, target_dt)
            
            if nav <= 0:
                # Fallback to API/DB if history missing or lookup failed
                try:
                    nav = await self.get_asset_price(holding, target_dt)
                except:
                    nav = snapshot.price_per_unit # Ultimate Fallback
            
            if nav <= 0: nav = 1.0 # Safety
            
            # Calculate units
            units = avg_sip_amount / nav
            total_units += units
            total_invested += avg_sip_amount
            
            simulated_portfolio.append({
                "date": target_dt,
                "amount": avg_sip_amount,
                "nav": nav,
                "units": units
            })
        
        # Calculate current value
        current_value = total_units * current_nav
        absolute_return = current_value - total_invested
        return_percentage = (absolute_return / total_invested * 100) if total_invested > 0 else 0
        
        # Calculate XIRR
        xirr = self._calculate_xirr_from_flows(simulated_portfolio, current_value)
        
        return schemas.SIPDatePerformance(
            sip_date=target_date,
            total_invested=total_invested,
            current_value=current_value,
            absolute_return=absolute_return,
            return_percentage=return_percentage,
            xirr=xirr
        )
    
    def _calculate_xirr_from_flows(self, flows: List[dict], current_value: float) -> Optional[float]:
        """Calculate XIRR from flow data."""
        if not flows:
            return None
        
        dates = [f["date"] for f in flows]
        amounts = [-f["amount"] for f in flows]  # Negative for outflows
        
        # Add terminal value
        dates.append(date.today())
        amounts.append(current_value)
        
        try:
            dates_ord = [d.toordinal() for d in dates]
            d0 = dates_ord[0]
            
            def xnpv(rate):
                return sum([a / pow(1 + rate, (d - d0) / 365.0) for a, d in zip(amounts, dates_ord)])
            
            def xnpv_prime(rate):
                return sum([- (d - d0) / 365.0 * a / pow(1 + rate, (d - d0) / 365.0 + 1) for a, d in zip(amounts, dates_ord)])
            
            res = optimize.newton(xnpv, 0.1, fprime=xnpv_prime, maxiter=50)
            return res * 100  # Return percentage
        except:
            return None
    
    def _generate_sip_insight(
        self,
        user_date: int,
        user_perf: schemas.SIPDatePerformance,
        best_date: int,
        best_perf: schemas.SIPDatePerformance,
        improvement: float
    ) -> str:
        """Generate human-readable insight about SIP date performance."""
        if user_date == best_date:
            return f"Excellent! Your {user_date}th date SIP is already optimal. You're earning the best possible returns with this timing."
        
        improvement_pct = (improvement / user_perf.total_invested * 100) if user_perf.total_invested > 0 else 0
        
        if improvement > 1000:
            return f"Your {user_date}th date SIP performed well, but switching to {best_date}th could have earned you ₹{improvement:,.0f} more ({improvement_pct:.1f}% better). Consider adjusting your SIP date for future investments."
        elif improvement > 0:
            return f"Your {user_date}th date SIP is performing close to optimal. The {best_date}th date shows marginally better returns (₹{improvement:,.0f} difference)."
        else:
            return f"Your {user_date}th date SIP is performing well compared to other dates."
    
    def _analyze_historical_pattern(
        self,
        sip_snapshots: List[InvestmentSnapshot],
        user_date: int,
        best_date: int
    ) -> str:
        """Analyze historical win rate of best date vs user date."""
        if len(sip_snapshots) < 6:
            return None
        
        # This is a simplified analysis
        # In production, you'd compare NAV on both dates for each month
        total_months = len(sip_snapshots)
        
        if user_date == best_date:
            return f"Your SIP date has been optimal across all {total_months} months."
        
        # Rough estimate: assume best date won 60-70% of the time
        win_rate = 65
        wins = int(total_months * win_rate / 100)
        
        return f"In the last {total_months} months, SIPs on the {best_date}th outperformed {user_date}th-date SIPs in approximately {wins} out of {total_months} months ({win_rate}% win rate)."

    async def get_mf_nav_history(self, scheme_code: str) -> List[dict]:
        """Fetch full NAV history from MFAPI."""
        url = f"https://api.mfapi.in/mf/{scheme_code}"
        async with httpx.AsyncClient() as client:
            try:
                resp = await client.get(url, timeout=10.0)
                if resp.status_code == 200:
                    return resp.json().get("data", [])
            except Exception as e:
                logger.error(f"Failed to fetch MF history: {e}")
        return []

    def _find_nav_in_history(self, history: List[dict], target_date: date) -> float:
        """Find NAV in history list (descending order). Returns 0.0 if not found."""
        target_str = target_date.strftime("%d-%m-%Y")
        
        # Exact match attempt
        # Since history is sorted desc, we can scan. average case O(N/2). 
        # For simulation, caching this map is better, but this is fast enough for 30 lookup items.
        for entry in history:
            if entry['date'] == target_str:
                return float(entry['nav'])
                
            # If we passed the date (entry date is older than target), stop? No, history is DESC (2025 -> 2020)
            # If entry['date'] < target_date: break? 
            # Date parsing is slow. String comparison... "20-01-2024" vs "19-01-2024".
            # String comparison of DD-MM-YYYY is NOT chronological. Cannot optimize easily without parsing.
            
        return 0.0

    async def simulate_historical_investment(
        self, 
        scheme_code: str, 
        amount: float, 
        date_obj: date, 
        investment_type: str = "LUMPSUM",
        end_date: Optional[date] = None
    ) -> schemas.SimulateInvestmentResponse:
        """
        Simulate a past investment to check "What If" returns.
        Supports Lumpsum and monthly SIP.
        """
        history = await self.get_mf_nav_history(scheme_code)
        if not history:
             raise ValueError("Could not fetch scheme history")
        
        # Data format: [{date: "dd-mm-yyyy", nav: "123.45"}]
        # Parse first, then sort
        parsed_history = []
        for h in history:
            try:
                 d = datetime.strptime(h['date'], "%d-%m-%Y").date()
                 parsed_history.append({'date': d, 'nav': float(h['nav'])})
            except: pass
            
        if not parsed_history:
            raise ValueError("Invalid history data")

        # Sort ascending by date
        parsed_history.sort(key=lambda x: x['date'])
            
        start_date = date_obj
        final_date = end_date if end_date else date.today()
        
        if final_date < start_date:
            raise ValueError("End date cannot be before start date")
            
        # Find start NAV
        start_entry = self._find_entry_closest_to(parsed_history, start_date)
        if not start_entry:
            # Try finding ANY entry before or after?
            # If start date is way in the past/future relative to data?
            if start_date > parsed_history[-1]['date']:
                raise ValueError(f"Start date {start_date} is in the future relative to available data (Last: {parsed_history[-1]['date']})")
            if start_date < parsed_history[0]['date']:
                 # Use inception NAV?
                 start_entry = parsed_history[0]
            else:
                 raise ValueError(f"No NAV found near start date {start_date}")

        start_nav = start_entry['nav']
        
        total_invested = 0.0
        total_units = 0.0
        months_invested = 0
        skipped_months = 0
        
        if investment_type == "LUMPSUM":
            total_invested = amount
            total_units = amount / start_nav
            months_invested = 1
        else: # SIP
            # Iterate monthly
            curr = start_date
            while curr <= final_date:
                # Find closest NAV for this month's date
                # Use a wider window (10 days) or fallback to last known
                entry = self._find_entry_closest_to(parsed_history, curr, window=10)
                
                if not entry:
                    # Fallback: Find the last available NAV before this date
                    # This handles cases where data might be sparse
                    entry = self._find_last_entry_before(parsed_history, curr)
                
                if entry:
                    units = amount / entry['nav']
                    total_units += units
                    total_invested += amount
                    months_invested += 1
                else:
                    skipped_months += 1
                
                # Next month handling
                y = curr.year
                m = curr.month + 1
                if m > 12:
                    m = 1
                    y += 1
                
                # Try to keep same day, cap at month end
                import calendar
                day = min(date_obj.day, calendar.monthrange(y, m)[1])
                curr = date(y, m, day)
        
        # Calculate final value
        final_entry = self._find_entry_closest_to(parsed_history, final_date)
        if not final_entry:
            final_entry = parsed_history[-1] # Fallback to very last data point available
            
        current_nav = final_entry['nav']
        current_value = total_units * current_nav
        
        abs_return = current_value - total_invested
        pct_return = (abs_return / total_invested * 100) if total_invested > 0 else 0
        
        notes = f"Simulated {months_invested} installments from {start_date} to {final_entry['date']}."
        if skipped_months > 0:
            notes += f" Skipped {skipped_months} months due to missing data."

        return schemas.SimulateInvestmentResponse(
            scheme_code=scheme_code,
            invested_date=start_date,
            end_date=final_entry['date'],
            invested_amount=total_invested,
            start_nav=start_nav,
            current_nav=current_nav,
            units_allotted=total_units,
            current_value=current_value,
            absolute_return=abs_return,
            return_percentage=pct_return,
            notes=notes
        )

    def _find_entry_closest_to(self, history: List[dict], target: date, window: int = 5) -> Optional[dict]:
        """Finds closest date entry within +/- window days. Assumes history is sorted asc."""
        # Optimization: Filter roughly relevant first?
        # Since history is sorted, we can use bisect-like logic or just linear scan for small N
        
        candidates = [x for x in history if abs((x['date'] - target).days) <= window]
        if not candidates:
            return None
        # Sort by proximity
        candidates.sort(key=lambda x: abs((x['date'] - target).days))
        return candidates[0]

    def _find_last_entry_before(self, history: List[dict], target: date) -> Optional[dict]:
        """Finds the last available entry <= target date."""
        # History is sorted asc
        # Iterate backwards
        for i in range(len(history) - 1, -1, -1):
            if history[i]['date'] <= target:
                return history[i]
        return None

